---
title: Part 2 两阶段检测器
createTime: 2025/08/05 16:38:33
permalink: /deeplearning/od/02/
---

[锚框](/deeplearning/od/01/#_2-锚框)用于提取物体的候选区域，然后再对区域进行分类识别。检测流程明显分为两步，因此称为两阶段检测，又称为基于区域的目标检测。

代表性的两阶段检测器就是 R-CNN 系列，包括 R-CNN、Fast R-CNN、Faster R-CNN。

由于两阶段检测器不是笔者学习的重点，因此仅作简单介绍。

## 1 R-CNN

R-CNN首先从输入图像中选取若干提议区域（锚框），并标注它们的类别和边界框。然后，用卷积神经网络对每个提议区域进行前向传播以抽取其特征，接下来用每个提议区域的特征来预测类别和边界框。

::: center
![1754383728873.webp](https://oss.yoake.cc/art/deeplearning/1754383728873.webp) 
:::

尽管 R-CNN 模型通过预训练的卷积神经网络有效地抽取了图像特征，但它的速度很慢。想象一下，我们可能从一张图像中选出上千个提议区域，这需要上千次的卷积神经网络的前向传播来执行目标检测。这种庞大的计算量使得 R-CNN 在现实世界中难以被广泛应用。

## 2 Fast R-CNN

R-CNN 的主要性能瓶颈在于，对每个提议区域，卷积神经网络的前向传播是独立的，而没有共享计算。 由于这些区域通常有重叠，独立的特征抽取会导致重复的计算。 

Fast R-CNN 对 R-CN N的主要改进之一，是仅在整张图像上执行卷积神经网络的前向传播。

::: center
![1754383811917.webp](https://oss.yoake.cc/art/deeplearning/1754383811917.webp) 
:::

1. 与R-CNN相比，Fast R-CNN用来提取特征的卷积神经网络的输入是整个图像。卷积神经网络的输出的形状为 $1 \times c \times h_1 \times w_1$；

2. 假设选择性搜索生成了$n$个提议区域。这些形状各异的提议区域在卷积神经网络的输出上分别标出了形状各异的兴趣区域。然后，这些感兴趣的区域需要进一步抽取出形状相同的特征（比如指定高度$h_2和宽度$w_2$），以便于连结后输出。为了实现这一目标，Fast R-CNN 引入了兴趣区域池化层，将卷积神经网络的输出和提议区域作为输入，输出连结后的各个提议区域抽取的特征，形状为 $n \times c \times h_2 \times w_2$；

3. 通过全连接层将输出形状变换为 $n \times d$，其中超参数$d$取决于模型设计；

4. 预测$n$个提议区域中每个区域的类别和边界框。更具体地说，在预测类别和边界框时，将全连接层的输出分别转换为形状为 $n \times q$（$q$是类别的数量）的输出和形状为 $n \times 4$ 的输出。其中预测类别时使用softmax回归。

## 3 Faster R-CNN

Faster R-CNN 提出将选择性搜索替换为区域提议网络，从而减少提议区域的生成数量，并保证目标检测的精度。

::: center
![1754384136086.webp](https://oss.yoake.cc/art/deeplearning/1754384136086.webp) 
:::

1. 使用填充为 1 的 3×3 的卷积层变换卷积神经网络的输出，并将输出通道数记为 $c$。这样，卷积神经网络为图像抽取的特征图中的每个单元均得到一个长度为 $c$ 的新特征。

2. 以特征图的每个像素为中心，生成多个不同大小和宽高比的锚框并标注它们。

3. 使用锚框中心单元长度为 $c$ 的特征，分别预测该锚框的二元类别（含目标还是背景）和边界框。

4. 使用非极大值抑制，从预测类别为目标的预测边界框中移除相似的结果。最终输出的预测边界框即是兴趣区域池化层所需的提议区域。

