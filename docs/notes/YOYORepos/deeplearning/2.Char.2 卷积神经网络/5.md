---
title: Part 5 NiN
createTime: 2025/08/05 09:34:27
permalink: /deeplearning/cnn/05/
---

卷积层的输入和输出由四维张量组成，每个轴分别对应样本、通道、高度和宽度。而全连接层的输入和输出是分别对应于样本和特征的二维张量。NiN 的想法是在每个像素上应用一个全连接层，或者说是 1×1 卷积层。

从另一个角度来看，NiN 将空间维度中的每个像素视为单个样本，将通道输出视为特征。

## 1 NiN 块与 NiN 网络

NiN 块以一个普通卷积层开始，紧跟两个 1×1 卷积层。普通卷积层的卷积核由用户设置。

NiN 网络在前面几个 NiN 块后叠加一个最大池化层，在最后一个 NiN 块后叠加一个平均池化层。并没有设置全连接层。

::: center
![1754358872724.webp](https://oss.yoake.cc/yoyopics/deeplearning/cnn/5/1754358872724.webp) 
:::

### 2 NiN 网络的 PyTorch 实现

和 VGG 一样，我们首先实现单个 NiN 块：

```py
def nin_block(in_channels, out_channels, kernel_size, strides, padding):
    return nn.Sequential(
        nn.Conv2d(in_channels, out_channels, kernel_size, strides, padding),
        nn.ReLU(),
        nn.Conv2d(out_channels, out_channels, kernel_size=1), nn.ReLU(),
        nn.Conv2d(out_channels, out_channels, kernel_size=1), nn.ReLU())
```

然后堆叠 NiN 块和池化层：

```py
net = nn.Sequential(
    nin_block(1, 96, kernel_size=11, strides=4, padding=0),
    nn.MaxPool2d(3, stride=2),
    nin_block(96, 256, kernel_size=5, strides=1, padding=2),
    nn.MaxPool2d(3, stride=2),
    nin_block(256, 384, kernel_size=3, strides=1, padding=1),
    nn.MaxPool2d(3, stride=2),
    nn.Dropout(0.5),
    # 标签类别数是10
    nin_block(384, 10, kernel_size=3, strides=1, padding=1),
    nn.AdaptiveAvgPool2d((1, 1)),
    # 将四维的输出转成二维的输出，其形状为(批量大小,10)
    nn.Flatten())
```

训练时学习率为 0.1，其他和 VGG、AlexNet 一致。