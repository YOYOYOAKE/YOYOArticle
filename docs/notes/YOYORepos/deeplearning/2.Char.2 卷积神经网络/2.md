---
title: Part 2 LeNet
createTime: 2025/08/04 10:07:46
permalink: /deeplearning/cnn/02/
---

LeNet 是最早发布的卷积神经网络之一，因其在计算机视觉任务中的高效性能而受到广泛关注。LeNet 在 1989 年被 Yann LeCun 提出并命名。

## 1 LeNet 结构

LeNet 由卷积编码器和全连接层稠密块两部分组成：

::: center
![1754273688571.webp](https://oss.yoake.cc/yoyopics/deeplearning/cnn/2/1754273688571.webp) 
:::

卷积编码器保罗两个卷积块，每个卷积块的基本单元是一个卷积层、一个 sigmoid 激活函数和一个平均池化层。每个卷积层使用 5×5 卷积核和一个 sigmoid 激活函数，将输入映射为多个通道的输出。第一卷积层有 6 个输出通道，第二卷积层有 16 个输出通道。每个 2×2 池化层将尺寸降低为原来的四分之一。

然后传递给全连接层稠密块。我们将这个四维输入转换成全连接层所期望的二维输入。这里的二维表示的第一个维度索引小批量中的样本，第二个维度给出每个样本的平面向量表示。LeNet 的稠密块有三个全连接层，分别有 120、84 和 10 个输出。因为我们在执行分类任务，所以输出层的 10 维对应于最后输出结果的数量。

## 2 LeNet 的 PyTorch 实现

使用 PyTorch 框架可以非常简单地实现 LeNet：

```py
net = nn.Sequential(
    # 第一卷积块
    nn.Conv2d(1, 6, kernel_size=5, padding=2), nn.Sigmoid(),
    nn.AvgPool2d(kernel_size=2, stride=2),
    # 第二卷积块
    nn.Conv2d(6, 16, kernel_size=5), nn.Sigmoid(),
    nn.AvgPool2d(kernel_size=2, stride=2),
    # 全连接层稠密块
    nn.Flatten(),
    nn.Linear(16 * 5 * 5, 120), nn.Sigmoid(),
    nn.Linear(120, 84), nn.Sigmoid(),
    nn.Linear(84, 10))
```