<!doctype html><html lang="zh-CN"><head><meta charset="utf-8" /><meta name="viewport" content="width=device-width,initial-scale=1" /><meta name="generator" content="VuePress 2.0.0-rc.24" /><meta name="theme" content="VuePress Theme Plume 1.0.0-rc.168" /><script id="check-mac-os">document.documentElement.classList.toggle('mac', /Mac|iPhone|iPod|iPad/i.test(navigator.platform))</script><script id="check-dark-mode">;(function () {const um= localStorage.getItem('vuepress-theme-appearance') || 'auto';const sm = window.matchMedia && window.matchMedia('(prefers-color-scheme: dark)').matches;const isDark = um === 'dark' || (um !== 'light' && sm);document.documentElement.dataset.theme = isDark ? 'dark' : 'light';})();</script><script type="application/ld+json">{"@context":"https://schema.org","@type":"Article","headline":"Part 5 多层感知机","image":["https://oss.yoake.cc/art/deeplearning/1749124913031.webp","https://oss.yoake.cc/art/deeplearning/1753692813234.webp"],"dateModified":null,"author":[]}</script><meta property="og:url" content="https://www.yoake.cc/deeplearning/basic/05/"><meta property="og:site_name" content="YOYOArticle"><meta property="og:title" content="Part 5 多层感知机"><meta property="og:description" content="神经网络之所以得名，是因为其中的参数相互连接，形成类似于神经系统一样的网状结构。在之前我们实现的线性回归和 softmax 回归并非严格意义上的神经网络，因为其只有一层。 softmax 回归在结构上是对输入做线性变换后再通过 softmax 函数得到概率分布，但其本质仍然是线性模型，无法处理复杂的非线性关系。 而在这里我们将会学习真正的深度神经网络。..."><meta property="og:type" content="article"><meta property="og:image" content="https://oss.yoake.cc/art/deeplearning/1749124913031.webp"><meta property="og:locale" content="zh-CN"><link rel="icon" href="https://oss.yoake.cc/art/avatars/avatar-round.webp"><title>Part 5 多层感知机 | YOYOArticle</title><meta name="description" content="神经网络之所以得名，是因为其中的参数相互连接，形成类似于神经系统一样的网状结构。在之前我们实现的线性回归和 softmax 回归并非严格意义上的神经网络，因为其只有一层。 softmax 回归在结构上是对输入做线性变换后再通过 softmax 函数得到概率分布，但其本质仍然是线性模型，无法处理复杂的非线性关系。 而在这里我们将会学习真正的深度神经网络。..."><link rel="preload" href="/assets/style-By-4q_3q.css" as="style"><link rel="stylesheet" href="/assets/style-By-4q_3q.css"><link rel="modulepreload" href="/assets/app-BvfsiuvN.js"><link rel="modulepreload" href="/assets/index.html-CBVkb75T.js"><link rel="prefetch" href="/assets/index.html-CK_ze-jf.js" as="script"><link rel="prefetch" href="/assets/index.html-BzpUqlaL.js" as="script"><link rel="prefetch" href="/assets/index.html-j9EEx738.js" as="script"><link rel="prefetch" href="/assets/index.html-BmvyfgKG.js" as="script"><link rel="prefetch" href="/assets/index.html-BDTB0csf.js" as="script"><link rel="prefetch" href="/assets/index.html-DgxxWklA.js" as="script"><link rel="prefetch" href="/assets/index.html-TkwADVKr.js" as="script"><link rel="prefetch" href="/assets/index.html-BcmqKb0g.js" as="script"><link rel="prefetch" href="/assets/index.html-crnbL1Rg.js" as="script"><link rel="prefetch" href="/assets/index.html-DWbiovgt.js" as="script"><link rel="prefetch" href="/assets/index.html-Dujeo-FI.js" as="script"><link rel="prefetch" href="/assets/index.html-C_ugH66i.js" as="script"><link rel="prefetch" href="/assets/index.html-oT5kf_qs.js" as="script"><link rel="prefetch" href="/assets/index.html-DBKC7f1M.js" as="script"><link rel="prefetch" href="/assets/index.html-BUq4twgh.js" as="script"><link rel="prefetch" href="/assets/index.html-MaCbFLXv.js" as="script"><link rel="prefetch" href="/assets/index.html-CiYqSMw5.js" as="script"><link rel="prefetch" href="/assets/index.html-yUYHZYHe.js" as="script"><link rel="prefetch" href="/assets/index.html-B7yCL4S5.js" as="script"><link rel="prefetch" href="/assets/index.html-BzEDHxek.js" as="script"><link rel="prefetch" href="/assets/index.html-DeY6j-Nx.js" as="script"><link rel="prefetch" href="/assets/index.html-yYyXhEjW.js" as="script"><link rel="prefetch" href="/assets/index.html-CRBNYYYq.js" as="script"><link rel="prefetch" href="/assets/index.html-C1LoiqyQ.js" as="script"><link rel="prefetch" href="/assets/index.html-B_tCSa5z.js" as="script"><link rel="prefetch" href="/assets/index.html-CkWF2lSc.js" as="script"><link rel="prefetch" href="/assets/index.html-DZs6xifk.js" as="script"><link rel="prefetch" href="/assets/index.html-B3BeH5-C.js" as="script"><link rel="prefetch" href="/assets/index.html-DvxYMtTt.js" as="script"><link rel="prefetch" href="/assets/index.html-CIOy8UVl.js" as="script"><link rel="prefetch" href="/assets/index.html-DLnvSkuW.js" as="script"><link rel="prefetch" href="/assets/index.html-DxxrGarZ.js" as="script"><link rel="prefetch" href="/assets/index.html-CFs3kkGi.js" as="script"><link rel="prefetch" href="/assets/index.html-CSnl4D-C.js" as="script"><link rel="prefetch" href="/assets/index.html-BnjUVabX.js" as="script"><link rel="prefetch" href="/assets/index.html-BcYBfUe6.js" as="script"><link rel="prefetch" href="/assets/index.html-gR9rVH8O.js" as="script"><link rel="prefetch" href="/assets/index.html-Dug0wpPL.js" as="script"><link rel="prefetch" href="/assets/index.html-jEqI8t6i.js" as="script"><link rel="prefetch" href="/assets/index.html-w47BT50O.js" as="script"><link rel="prefetch" href="/assets/index.html-rOZl88GL.js" as="script"><link rel="prefetch" href="/assets/index.html-BdjFUn3o.js" as="script"><link rel="prefetch" href="/assets/index.html-B_iYP-UE.js" as="script"><link rel="prefetch" href="/assets/index.html-sMXgFEvc.js" as="script"><link rel="prefetch" href="/assets/index.html-oGM2eHbr.js" as="script"><link rel="prefetch" href="/assets/index.html-DqQ680Nl.js" as="script"><link rel="prefetch" href="/assets/index.html-zbMAkEp7.js" as="script"><link rel="prefetch" href="/assets/index.html-DiRM8TJi.js" as="script"><link rel="prefetch" href="/assets/index.html-CVMSgBHJ.js" as="script"><link rel="prefetch" href="/assets/index.html-NkuHPCWU.js" as="script"><link rel="prefetch" href="/assets/index.html-CEZG_A1h.js" as="script"><link rel="prefetch" href="/assets/index.html-CUr_WBqN.js" as="script"><link rel="prefetch" href="/assets/index.html-BRMyuwOg.js" as="script"><link rel="prefetch" href="/assets/index.html-CK-yDjqV.js" as="script"><link rel="prefetch" href="/assets/index.html-D8dYF2h2.js" as="script"><link rel="prefetch" href="/assets/index.html-CU2RSVkU.js" as="script"><link rel="prefetch" href="/assets/index.html-D43IR2Zs.js" as="script"><link rel="prefetch" href="/assets/index.html-KZqorH7s.js" as="script"><link rel="prefetch" href="/assets/index.html-C7OwpcaF.js" as="script"><link rel="prefetch" href="/assets/index.html-DnTWO_mk.js" as="script"><link rel="prefetch" href="/assets/index.html-BbvItsJN.js" as="script"><link rel="prefetch" href="/assets/index.html-Do1yeHDk.js" as="script"><link rel="prefetch" href="/assets/index.html-j4WGYsnR.js" as="script"><link rel="prefetch" href="/assets/index.html-DF0yD1ft.js" as="script"><link rel="prefetch" href="/assets/index.html-D2TfHad7.js" as="script"><link rel="prefetch" href="/assets/index.html-j7Lg75Ee.js" as="script"><link rel="prefetch" href="/assets/index.html-Cky6k4hj.js" as="script"><link rel="prefetch" href="/assets/index.html-Da2smCnI.js" as="script"><link rel="prefetch" href="/assets/index.html-Zkam1lTn.js" as="script"><link rel="prefetch" href="/assets/index.html-DEWXbMLd.js" as="script"><link rel="prefetch" href="/assets/index.html-BLWaJjRk.js" as="script"><link rel="prefetch" href="/assets/index.html-D99lA15F.js" as="script"><link rel="prefetch" href="/assets/index.html-B16dDwMA.js" as="script"><link rel="prefetch" href="/assets/index.html-Bh56Vddv.js" as="script"><link rel="prefetch" href="/assets/index.html-Brrss0M1.js" as="script"><link rel="prefetch" href="/assets/index.html-Dwwg-S1M.js" as="script"><link rel="prefetch" href="/assets/index.html-Bqn6XvnH.js" as="script"><link rel="prefetch" href="/assets/index.html-CBarPKBm.js" as="script"><link rel="prefetch" href="/assets/index.html-CvAwFqBQ.js" as="script"><link rel="prefetch" href="/assets/index.html-RfmiUeKj.js" as="script"><link rel="prefetch" href="/assets/index.html-BKr-xY_q.js" as="script"><link rel="prefetch" href="/assets/index.html-KP9LyPSi.js" as="script"><link rel="prefetch" href="/assets/index.html-Cl0qCb24.js" as="script"><link rel="prefetch" href="/assets/index.html-09y2UxPi.js" as="script"><link rel="prefetch" href="/assets/index.html-BhpNIJI6.js" as="script"><link rel="prefetch" href="/assets/index.html-LAhQZfHT.js" as="script"><link rel="prefetch" href="/assets/index.html-CBFhlGa_.js" as="script"><link rel="prefetch" href="/assets/index.html-C_yXHupq.js" as="script"><link rel="prefetch" href="/assets/index.html-ZPF0Is-9.js" as="script"><link rel="prefetch" href="/assets/index.html-C9S5wjee.js" as="script"><link rel="prefetch" href="/assets/index.html-B8WgxmeU.js" as="script"><link rel="prefetch" href="/assets/index.html-j6AotGJd.js" as="script"><link rel="prefetch" href="/assets/index.html-Ba4ZD49y.js" as="script"><link rel="prefetch" href="/assets/index.html-T7Wu7JTs.js" as="script"><link rel="prefetch" href="/assets/index.html-CfKvMmAy.js" as="script"><link rel="prefetch" href="/assets/index.html-BBdJ95ZL.js" as="script"><link rel="prefetch" href="/assets/index.html-BkGaJnBX.js" as="script"><link rel="prefetch" href="/assets/index.html-aZWlnQVE.js" as="script"><link rel="prefetch" href="/assets/index.html-9MAHa-8P.js" as="script"><link rel="prefetch" href="/assets/index.html-s2QEaw61.js" as="script"><link rel="prefetch" href="/assets/index.html-BT1WTJgs.js" as="script"><link rel="prefetch" href="/assets/index.html-6T9KIxbb.js" as="script"><link rel="prefetch" href="/assets/index.html-CGVKbLFT.js" as="script"><link rel="prefetch" href="/assets/index.html-D4vDQAsv.js" as="script"><link rel="prefetch" href="/assets/index.html-D-89eL-Q.js" as="script"><link rel="prefetch" href="/assets/index.html-tmNwxKUN.js" as="script"><link rel="prefetch" href="/assets/404.html-C9Vsq-05.js" as="script"><link rel="prefetch" href="/assets/index.html-MKMxpKbU.js" as="script"><link rel="prefetch" href="/assets/index.html-DhUCOfmS.js" as="script"><link rel="prefetch" href="/assets/index.html-NFHSH7qL.js" as="script"><link rel="prefetch" href="/assets/index.html-BdvXkE-L.js" as="script"><link rel="prefetch" href="/assets/index.html-oT5kf_qs.js" as="script"><link rel="prefetch" href="/assets/index.html-Bn9s9o01.js" as="script"><link rel="prefetch" href="/assets/index.html-8o4tfYpu.js" as="script"><link rel="prefetch" href="/assets/index.html-CDR7ovkz.js" as="script"><link rel="prefetch" href="/assets/mermaid.esm.min-Bnu2h4fS.js" as="script"><link rel="prefetch" href="/assets/photoswipe.esm-CKV1Bsxh.js" as="script"><link rel="prefetch" href="/assets/searchBox-default-XDpIiE0u.js" as="script"><link rel="prefetch" href="/assets/SearchBox-DUcwzDzE.js" as="script"></head><body><div id="app"><!--[--><!--[--><div class="theme-plume vp-layout" vp-container data-v-b0769c2c><!--[--><!--[--><!--]--><!--[--><span tabindex="-1" data-v-bd138198></span><a href="#VPContent" class="vp-skip-link visually-hidden" data-v-bd138198> Skip to content </a><!--]--><!----><header class="vp-nav" data-v-b0769c2c data-v-5f0ed928><div class="vp-navbar" vp-navbar data-v-5f0ed928 data-v-b7e9500d><div class="wrapper" data-v-b7e9500d><div class="container" data-v-b7e9500d><div class="title" data-v-b7e9500d><div class="vp-navbar-title has-sidebar" data-v-b7e9500d data-v-96d9846e><a class="vp-link link no-icon title" href="/" data-v-96d9846e><!--[--><!--[--><!--]--><!--[--><!--[--><!--[--><img class="vp-image dark logo" style="" src="https://oss.yoake.cc/art/avatars/avatar-round.webp" alt data-v-0505fba8><!--]--><!--[--><img class="vp-image light logo" style="" src="https://oss.yoake.cc/art/avatars/avatar-round.webp" alt data-v-0505fba8><!--]--><!--]--><!--]--><span data-v-96d9846e>YOYOArticle</span><!--[--><!--]--><!--]--><!----></a></div></div><div class="content" data-v-b7e9500d><div class="content-body" data-v-b7e9500d><!--[--><!--]--><div class="vp-navbar-search search" data-v-b7e9500d><div class="search-wrapper" data-v-716ef9df><!----><div id="local-search" data-v-716ef9df><button type="button" class="mini-search mini-search-button" aria-label="搜索文档" data-v-716ef9df><span class="mini-search-button-container"><span class="mini-search-search-icon vpi-mini-search" aria-label="search icon"></span><span class="mini-search-button-placeholder">搜索文档</span></span><span class="mini-search-button-keys"><kbd class="mini-search-button-key"></kbd><kbd class="mini-search-button-key">K</kbd></span></button></div></div></div><!--[--><!--]--><nav aria-labelledby="main-nav-aria-label" class="vp-navbar-menu menu" data-v-b7e9500d data-v-1c3650d6><span id="main-nav-aria-label" class="visually-hidden" data-v-1c3650d6>Main Navigation</span><!--[--><!--[--><a class="vp-link link navbar-menu-link" href="/" tabindex="0" data-v-1c3650d6 data-v-b4e36f3c><!--[--><!----><span data-v-b4e36f3c>首页</span><!----><!--]--><!----></a><!--]--><!--[--><a class="vp-link link navbar-menu-link" href="/articles/" tabindex="0" data-v-1c3650d6 data-v-b4e36f3c><!--[--><!----><span data-v-b4e36f3c>文章</span><!----><!--]--><!----></a><!--]--><!--[--><a class="vp-link link navbar-menu-link" href="/record/2025/" tabindex="0" data-v-1c3650d6 data-v-b4e36f3c><!--[--><!----><span data-v-b4e36f3c>周记</span><!----><!--]--><!----></a><!--]--><!--[--><a class="vp-link link navbar-menu-link" href="/friends/" tabindex="0" data-v-1c3650d6 data-v-b4e36f3c><!--[--><!----><span data-v-b4e36f3c>友链</span><!----><!--]--><!----></a><!--]--><!--[--><a class="vp-link link navbar-menu-link" href="/memo/" tabindex="0" data-v-1c3650d6 data-v-b4e36f3c><!--[--><!----><span data-v-b4e36f3c>备忘录</span><!----><!--]--><!----></a><!--]--><!--[--><div class="vp-flyout vp-navbar-menu-group" data-v-1c3650d6 data-v-6f8dd9d2><button type="button" class="button" aria-haspopup="true" aria-expanded="false" data-v-6f8dd9d2><span class="text" data-v-6f8dd9d2><!----><!----><span data-v-6f8dd9d2>知识库</span><!----><span class="vpi-chevron-down text-icon" data-v-6f8dd9d2></span></span></button><div class="menu" data-v-6f8dd9d2><div class="vp-menu" data-v-6f8dd9d2 data-v-fc202394><div class="items" data-v-fc202394><!--[--><!--[--><div class="vp-menu-link" data-v-fc202394 data-v-46760bfc><a class="vp-link link" href="/graphics/" data-v-46760bfc><!--[--><!----> 现代计算机图形学入门 <!----><!--]--><!----></a></div><!--]--><!--[--><div class="vp-menu-link" data-v-fc202394 data-v-46760bfc><a class="vp-link link" href="/java/" data-v-46760bfc><!--[--><!----> 从零开始学 Java <!----><!--]--><!----></a></div><!--]--><!--[--><div class="vp-menu-link" data-v-fc202394 data-v-46760bfc><a class="vp-link link" href="/deeplearning/" data-v-46760bfc><!--[--><!----> 深度学习浅水区 <!----><!--]--><!----></a></div><!--]--><!--[--><div class="vp-menu-link" data-v-fc202394 data-v-46760bfc><a class="vp-link link" href="/react/" data-v-46760bfc><!--[--><!----> React 快速上手 <!----><!--]--><!----></a></div><!--]--><!--[--><div class="vp-menu-link" data-v-fc202394 data-v-46760bfc><a class="vp-link link" href="/type-challanges/" data-v-46760bfc><!--[--><!----> TypeScript 类型体操 <!----><!--]--><!----></a></div><!--]--><!--[--><div class="vp-menu-link" data-v-fc202394 data-v-46760bfc><a class="vp-link link" href="/web3d/" data-v-46760bfc><!--[--><!----> Web 3D 基础 <!----><!--]--><!----></a></div><!--]--><!--]--></div><!--[--><!--]--></div></div></div><!--]--><!--]--></nav><!--[--><!--]--><!----><div class="vp-navbar-appearance appearance" data-v-b7e9500d data-v-abcc3a19><button class="vp-switch vp-switch-appearance" type="button" role="switch" title aria-checked="false" data-v-abcc3a19 data-v-ec1a32b9 data-v-295f0cc3><span class="check" data-v-295f0cc3><span class="icon" data-v-295f0cc3><!--[--><span class="vpi-sun sun" data-v-ec1a32b9></span><span class="vpi-moon moon" data-v-ec1a32b9></span><!--]--></span></span></button></div><div class="vp-social-links vp-navbar-social-links social-links" data-v-b7e9500d data-v-fdc4f9a6 data-v-2dcfcb0d><!--[--><a class="vp-social-link no-icon" href="https://github.com/yoyoyoake/" aria-label="github" target="_blank" rel="noopener" data-v-2dcfcb0d data-v-5257a306><span class="vpi-social-github" /></a><!--]--></div><div class="vp-flyout vp-navbar-extra extra" data-v-b7e9500d data-v-c663091e data-v-6f8dd9d2><button type="button" class="button" aria-haspopup="true" aria-expanded="false" aria-label="extra navigation" data-v-6f8dd9d2><span class="vpi-more-horizontal icon" data-v-6f8dd9d2></span></button><div class="menu" data-v-6f8dd9d2><div class="vp-menu" data-v-6f8dd9d2 data-v-fc202394><!----><!--[--><!--[--><!----><div class="group" data-v-c663091e><div class="item appearance" data-v-c663091e><p class="label" data-v-c663091e>外观</p><div class="appearance-action" data-v-c663091e><button class="vp-switch vp-switch-appearance" type="button" role="switch" title aria-checked="false" data-v-c663091e data-v-ec1a32b9 data-v-295f0cc3><span class="check" data-v-295f0cc3><span class="icon" data-v-295f0cc3><!--[--><span class="vpi-sun sun" data-v-ec1a32b9></span><span class="vpi-moon moon" data-v-ec1a32b9></span><!--]--></span></span></button></div></div></div><div class="group" data-v-c663091e><div class="item social-links" data-v-c663091e><div class="vp-social-links social-links-list" data-v-c663091e data-v-2dcfcb0d><!--[--><a class="vp-social-link no-icon" href="https://github.com/yoyoyoake/" aria-label="github" target="_blank" rel="noopener" data-v-2dcfcb0d data-v-5257a306><span class="vpi-social-github" /></a><!--]--></div></div></div><!--]--><!--]--></div></div></div><!--[--><!--]--><button type="button" class="vp-navbar-hamburger hamburger" aria-label="mobile navigation" aria-expanded="false" aria-controls="nav-screen" data-v-b7e9500d data-v-90db9727><span class="container" data-v-90db9727><span class="top" data-v-90db9727></span><span class="middle" data-v-90db9727></span><span class="bottom" data-v-90db9727></span></span></button></div></div></div></div><div class="divider" data-v-b7e9500d><div class="divider-line" data-v-b7e9500d></div></div></div><!----></header><div class="vp-local-nav reached-top" data-v-b0769c2c data-v-e13c227e><button class="menu" aria-expanded="false" aria-controls="SidebarNav" data-v-e13c227e><span class="vpi-align-left menu-icon" data-v-e13c227e></span><span class="menu-text" data-v-e13c227e>Menu</span></button><div class="vp-local-nav-outline-dropdown" style="--vp-vh:0px;" data-v-e13c227e data-v-ea4dc74d><button data-v-ea4dc74d>返回顶部</button><!----></div></div><aside class="vp-sidebar" vp-sidebar data-v-b0769c2c data-v-0d3ce494><div class="curtain" data-v-0d3ce494></div><nav id="SidebarNav" class="nav" aria-labelledby="sidebar-aria-label" tabindex="-1" data-v-0d3ce494><span id="sidebar-aria-label" class="visually-hidden" data-v-0d3ce494> Sidebar Navigation </span><!--[--><!--]--><!--[--><div class="no-transition group" data-v-4e2ff754><section class="vp-sidebar-item sidebar-item level-0 collapsible has-active" data-v-4e2ff754 data-v-bcd815be><div class="item" role="button" tabindex="0" data-v-bcd815be><div class="indicator" data-v-bcd815be></div><!----><h2 class="text" data-v-bcd815be><span data-v-bcd815be>Char.1 基础知识</span><!----></h2><div class="caret" role="button" aria-label="toggle section" tabindex="0" data-v-bcd815be><span class="vpi-chevron-right caret-icon" data-v-bcd815be></span></div></div><div data-v-bcd815be data-v-bcd815be><div class="items" data-v-bcd815be><!--[--><div class="vp-sidebar-item sidebar-item level-1 is-link" data-v-bcd815be data-v-bcd815be><div class="item" data-v-bcd815be><div class="indicator" data-v-bcd815be></div><!----><a class="vp-link link link" href="/deeplearning/basic/01/" data-v-bcd815be><!--[--><p class="text" data-v-bcd815be><span data-v-bcd815be>Part 1 PyTorch 张量操作</span><!----></p><!--]--><!----></a><!----></div><!----></div><div class="vp-sidebar-item sidebar-item level-1 is-link" data-v-bcd815be data-v-bcd815be><div class="item" data-v-bcd815be><div class="indicator" data-v-bcd815be></div><!----><a class="vp-link link link" href="/deeplearning/basic/02/" data-v-bcd815be><!--[--><p class="text" data-v-bcd815be><span data-v-bcd815be>Part 2 梯度与自动微分</span><!----></p><!--]--><!----></a><!----></div><!----></div><div class="vp-sidebar-item sidebar-item level-1 is-link" data-v-bcd815be data-v-bcd815be><div class="item" data-v-bcd815be><div class="indicator" data-v-bcd815be></div><!----><a class="vp-link link link" href="/deeplearning/basic/03/" data-v-bcd815be><!--[--><p class="text" data-v-bcd815be><span data-v-bcd815be>Part 3 线性神经网络</span><!----></p><!--]--><!----></a><!----></div><!----></div><div class="vp-sidebar-item sidebar-item level-1 is-link" data-v-bcd815be data-v-bcd815be><div class="item" data-v-bcd815be><div class="indicator" data-v-bcd815be></div><!----><a class="vp-link link link" href="/deeplearning/basic/04/" data-v-bcd815be><!--[--><p class="text" data-v-bcd815be><span data-v-bcd815be>Part 4 softmax 回归</span><!----></p><!--]--><!----></a><!----></div><!----></div><div class="vp-sidebar-item sidebar-item level-1 is-link" data-v-bcd815be data-v-bcd815be><div class="item" data-v-bcd815be><div class="indicator" data-v-bcd815be></div><!----><a class="vp-link link link" href="/deeplearning/basic/05/" data-v-bcd815be><!--[--><p class="text" data-v-bcd815be><span data-v-bcd815be>Part 5 多层感知机</span><!----></p><!--]--><!----></a><!----></div><!----></div><!--]--></div></div></section></div><div class="no-transition group" data-v-4e2ff754><section class="vp-sidebar-item sidebar-item level-0 collapsible" data-v-4e2ff754 data-v-bcd815be><div class="item" role="button" tabindex="0" data-v-bcd815be><div class="indicator" data-v-bcd815be></div><!----><h2 class="text" data-v-bcd815be><span data-v-bcd815be>Char.2 卷积神经网络</span><!----></h2><div class="caret" role="button" aria-label="toggle section" tabindex="0" data-v-bcd815be><span class="vpi-chevron-right caret-icon" data-v-bcd815be></span></div></div><div data-v-bcd815be data-v-bcd815be><div class="items" data-v-bcd815be><!--[--><div class="vp-sidebar-item sidebar-item level-1 is-link" data-v-bcd815be data-v-bcd815be><div class="item" data-v-bcd815be><div class="indicator" data-v-bcd815be></div><!----><a class="vp-link link link" href="/deeplearning/cnn/01/" data-v-bcd815be><!--[--><p class="text" data-v-bcd815be><span data-v-bcd815be>Part 1 卷积神经网络基本原理</span><!----></p><!--]--><!----></a><!----></div><!----></div><div class="vp-sidebar-item sidebar-item level-1 is-link" data-v-bcd815be data-v-bcd815be><div class="item" data-v-bcd815be><div class="indicator" data-v-bcd815be></div><!----><a class="vp-link link link" href="/deeplearning/cnn/02/" data-v-bcd815be><!--[--><p class="text" data-v-bcd815be><span data-v-bcd815be>Part 2 LeNet</span><!----></p><!--]--><!----></a><!----></div><!----></div><div class="vp-sidebar-item sidebar-item level-1 is-link" data-v-bcd815be data-v-bcd815be><div class="item" data-v-bcd815be><div class="indicator" data-v-bcd815be></div><!----><a class="vp-link link link" href="/deeplearning/cnn/03/" data-v-bcd815be><!--[--><p class="text" data-v-bcd815be><span data-v-bcd815be>Paet 3 AlexNet</span><!----></p><!--]--><!----></a><!----></div><!----></div><div class="vp-sidebar-item sidebar-item level-1 is-link" data-v-bcd815be data-v-bcd815be><div class="item" data-v-bcd815be><div class="indicator" data-v-bcd815be></div><!----><a class="vp-link link link" href="/deeplearning/cnn/04/" data-v-bcd815be><!--[--><p class="text" data-v-bcd815be><span data-v-bcd815be>Part 4 VGG</span><!----></p><!--]--><!----></a><!----></div><!----></div><div class="vp-sidebar-item sidebar-item level-1 is-link" data-v-bcd815be data-v-bcd815be><div class="item" data-v-bcd815be><div class="indicator" data-v-bcd815be></div><!----><a class="vp-link link link" href="/deeplearning/cnn/05/" data-v-bcd815be><!--[--><p class="text" data-v-bcd815be><span data-v-bcd815be>Part 5 NiN</span><!----></p><!--]--><!----></a><!----></div><!----></div><div class="vp-sidebar-item sidebar-item level-1 is-link" data-v-bcd815be data-v-bcd815be><div class="item" data-v-bcd815be><div class="indicator" data-v-bcd815be></div><!----><a class="vp-link link link" href="/deeplearning/cnn/06/" data-v-bcd815be><!--[--><p class="text" data-v-bcd815be><span data-v-bcd815be>Part 6 GoogLeNet</span><!----></p><!--]--><!----></a><!----></div><!----></div><div class="vp-sidebar-item sidebar-item level-1 is-link" data-v-bcd815be data-v-bcd815be><div class="item" data-v-bcd815be><div class="indicator" data-v-bcd815be></div><!----><a class="vp-link link link" href="/deeplearning/cnn/07/" data-v-bcd815be><!--[--><p class="text" data-v-bcd815be><span data-v-bcd815be>Part 7 ResNet</span><!----></p><!--]--><!----></a><!----></div><!----></div><div class="vp-sidebar-item sidebar-item level-1 is-link" data-v-bcd815be data-v-bcd815be><div class="item" data-v-bcd815be><div class="indicator" data-v-bcd815be></div><!----><a class="vp-link link link" href="/deeplearning/cnn/08/" data-v-bcd815be><!--[--><p class="text" data-v-bcd815be><span data-v-bcd815be>Part 8 DenseNet</span><!----></p><!--]--><!----></a><!----></div><!----></div><!--]--></div></div></section></div><div class="no-transition group" data-v-4e2ff754><section class="vp-sidebar-item sidebar-item level-0 collapsible" data-v-4e2ff754 data-v-bcd815be><div class="item" role="button" tabindex="0" data-v-bcd815be><div class="indicator" data-v-bcd815be></div><!----><h2 class="text" data-v-bcd815be><span data-v-bcd815be>Char.3 目标检测基础</span><!----></h2><div class="caret" role="button" aria-label="toggle section" tabindex="0" data-v-bcd815be><span class="vpi-chevron-right caret-icon" data-v-bcd815be></span></div></div><div data-v-bcd815be data-v-bcd815be><div class="items" data-v-bcd815be><!--[--><div class="vp-sidebar-item sidebar-item level-1 is-link" data-v-bcd815be data-v-bcd815be><div class="item" data-v-bcd815be><div class="indicator" data-v-bcd815be></div><!----><a class="vp-link link link" href="/deeplearning/od/01/" data-v-bcd815be><!--[--><p class="text" data-v-bcd815be><span data-v-bcd815be>Part 1 目标检测基本概念</span><!----></p><!--]--><!----></a><!----></div><!----></div><div class="vp-sidebar-item sidebar-item level-1 is-link" data-v-bcd815be data-v-bcd815be><div class="item" data-v-bcd815be><div class="indicator" data-v-bcd815be></div><!----><a class="vp-link link link" href="/deeplearning/od/02/" data-v-bcd815be><!--[--><p class="text" data-v-bcd815be><span data-v-bcd815be>Part 2 两阶段检测器</span><!----></p><!--]--><!----></a><!----></div><!----></div><div class="vp-sidebar-item sidebar-item level-1 is-link" data-v-bcd815be data-v-bcd815be><div class="item" data-v-bcd815be><div class="indicator" data-v-bcd815be></div><!----><a class="vp-link link link" href="/deeplearning/od/03/" data-v-bcd815be><!--[--><p class="text" data-v-bcd815be><span data-v-bcd815be>Part 3 单阶段检测器 SSD</span><!----></p><!--]--><!----></a><!----></div><!----></div><!--]--></div></div></section></div><div class="no-transition group" data-v-4e2ff754><section class="vp-sidebar-item sidebar-item level-0 collapsible" data-v-4e2ff754 data-v-bcd815be><div class="item" role="button" tabindex="0" data-v-bcd815be><div class="indicator" data-v-bcd815be></div><!----><h2 class="text" data-v-bcd815be><span data-v-bcd815be>Char.4 YOLOv8</span><!----></h2><div class="caret" role="button" aria-label="toggle section" tabindex="0" data-v-bcd815be><span class="vpi-chevron-right caret-icon" data-v-bcd815be></span></div></div><div data-v-bcd815be data-v-bcd815be><div class="items" data-v-bcd815be><!--[--><div class="vp-sidebar-item sidebar-item level-1 is-link" data-v-bcd815be data-v-bcd815be><div class="item" data-v-bcd815be><div class="indicator" data-v-bcd815be></div><!----><a class="vp-link link link" href="/deeplearning/yolo/01/" data-v-bcd815be><!--[--><p class="text" data-v-bcd815be><span data-v-bcd815be>Part 1 YOLOv8 结构</span><!----></p><!--]--><!----></a><!----></div><!----></div><div class="vp-sidebar-item sidebar-item level-1 is-link" data-v-bcd815be data-v-bcd815be><div class="item" data-v-bcd815be><div class="indicator" data-v-bcd815be></div><!----><a class="vp-link link link" href="/deeplearning/yolo/02/" data-v-bcd815be><!--[--><p class="text" data-v-bcd815be><span data-v-bcd815be>Part 2 Ultralytics 模型定义</span><!----></p><!--]--><!----></a><!----></div><!----></div><div class="vp-sidebar-item sidebar-item level-1 is-link" data-v-bcd815be data-v-bcd815be><div class="item" data-v-bcd815be><div class="indicator" data-v-bcd815be></div><!----><a class="vp-link link link" href="/deeplearning/yolo/03/" data-v-bcd815be><!--[--><p class="text" data-v-bcd815be><span data-v-bcd815be>Part 3 YOLOv8 训练与预测</span><!----></p><!--]--><!----></a><!----></div><!----></div><!--]--></div></div></section></div><div class="no-transition group" data-v-4e2ff754><section class="vp-sidebar-item sidebar-item level-0 collapsible" data-v-4e2ff754 data-v-bcd815be><div class="item" role="button" tabindex="0" data-v-bcd815be><div class="indicator" data-v-bcd815be></div><!----><h2 class="text" data-v-bcd815be><span data-v-bcd815be>Char.5 注意力机制</span><!----></h2><div class="caret" role="button" aria-label="toggle section" tabindex="0" data-v-bcd815be><span class="vpi-chevron-right caret-icon" data-v-bcd815be></span></div></div><div data-v-bcd815be data-v-bcd815be><div class="items" data-v-bcd815be><!--[--><div class="vp-sidebar-item sidebar-item level-1 is-link" data-v-bcd815be data-v-bcd815be><div class="item" data-v-bcd815be><div class="indicator" data-v-bcd815be></div><!----><a class="vp-link link link" href="/deeplearning/attention/01/" data-v-bcd815be><!--[--><p class="text" data-v-bcd815be><span data-v-bcd815be>Part 1 注意力机制原理</span><!----></p><!--]--><!----></a><!----></div><!----></div><div class="vp-sidebar-item sidebar-item level-1 is-link" data-v-bcd815be data-v-bcd815be><div class="item" data-v-bcd815be><div class="indicator" data-v-bcd815be></div><!----><a class="vp-link link link" href="/deeplearning/attention/02/" data-v-bcd815be><!--[--><p class="text" data-v-bcd815be><span data-v-bcd815be>Part 2 常见的注意力机制</span><!----></p><!--]--><!----></a><!----></div><!----></div><!--]--></div></div></section></div><!--]--><!--[--><!--]--></nav></aside><!--[--><div id="VPContent" vp-content class="vp-content has-sidebar" data-v-b0769c2c data-v-1b511400><div class="vp-doc-container has-sidebar has-aside" data-v-1b511400 data-v-1b79a3f7><!--[--><!--]--><div class="container" data-v-1b79a3f7><div class="aside" vp-outline data-v-1b79a3f7><div class="aside-curtain" data-v-1b79a3f7></div><div class="aside-container" data-v-1b79a3f7><div class="aside-content" data-v-1b79a3f7><div class="vp-doc-aside" data-v-1b79a3f7 data-v-459014f4><!--[--><!--]--><!--[--><!--]--><nav aria-labelledby="doc-outline-aria-label" class="vp-doc-aside-outline" role="navigation" data-v-459014f4 data-v-1093d6f2><div class="content" data-v-1093d6f2><div class="outline-marker" data-v-1093d6f2></div><div id="doc-outline-aria-label" aria-level="2" class="outline-title" role="heading" data-v-1093d6f2><span data-v-1093d6f2>此页内容</span><span class="vpi-print icon" data-v-1093d6f2></span></div><ul class="root" data-v-1093d6f2 data-v-3bee6071><!--[--><!--]--></ul></div></nav><!--[--><!--]--><div class="spacer" data-v-459014f4></div><!--[--><!--]--></div></div></div></div><div class="content" data-v-1b79a3f7><div class="content-container" data-v-1b79a3f7><!--[--><!--]--><main class="main" data-v-1b79a3f7><nav class="vp-breadcrumb" data-v-1b79a3f7 data-v-267eeda6><ol vocab="https://schema.org/" typeof="BreadcrumbList" data-v-267eeda6><!--[--><li property="itemListElement" typeof="ListItem" data-v-267eeda6><a class="vp-link link breadcrumb" href="/" property="item" typeof="WebPage" data-v-267eeda6><!--[-->首页<!--]--><!----></a><span class="vpi-chevron-right" data-v-267eeda6></span><meta property="name" content="首页" data-v-267eeda6><meta property="position" content="1" data-v-267eeda6></li><li property="itemListElement" typeof="ListItem" data-v-267eeda6><a class="vp-link link breadcrumb" href="/deeplearning/" property="item" typeof="WebPage" data-v-267eeda6><!--[-->深度学习浅水区<!--]--><!----></a><span class="vpi-chevron-right" data-v-267eeda6></span><meta property="name" content="深度学习浅水区" data-v-267eeda6><meta property="position" content="2" data-v-267eeda6></li><li property="itemListElement" typeof="ListItem" data-v-267eeda6><span class="vp-link breadcrumb" property="item" typeof="WebPage" data-v-267eeda6><!--[-->Char.1 基础知识<!--]--><!----></span><span class="vpi-chevron-right" data-v-267eeda6></span><meta property="name" content="Char.1 基础知识" data-v-267eeda6><meta property="position" content="3" data-v-267eeda6></li><li property="itemListElement" typeof="ListItem" data-v-267eeda6><a class="vp-link link breadcrumb current" href="/deeplearning/basic/05/" property="item" typeof="WebPage" data-v-267eeda6><!--[-->Part 5 多层感知机<!--]--><!----></a><!----><meta property="name" content="Part 5 多层感知机" data-v-267eeda6><meta property="position" content="4" data-v-267eeda6></li><!--]--></ol></nav><!--[--><!--]--><!--[--><h1 class="vp-doc-title page-title" data-v-2182e1ca><!----> Part 5 多层感知机 <!----></h1><div class="vp-doc-meta" data-v-2182e1ca><!--[--><!--]--><p class="reading-time" data-v-2182e1ca><span class="vpi-books icon" data-v-2182e1ca></span><span data-v-2182e1ca>约 2460 字</span><span data-v-2182e1ca>大约 8 分钟</span></p><!----><!--[--><!--]--><!----></div><!--]--><!--[--><!--]--><div class="_deeplearning_basic_05_ external-link-icon-enabled vp-doc plume-content" vp-content data-v-1b79a3f7><!--[--><!--]--><div data-v-1b79a3f7><p>神经网络之所以得名，是因为其中的参数相互连接，形成类似于神经系统一样的网状结构。在之前我们实现的线性回归和 softmax 回归并非严格意义上的神经网络，因为其只有一层。</p><p>softmax 回归在结构上是对输入做线性变换后再通过 softmax 函数得到概率分布，但其本质仍然是线性模型，无法处理复杂的非线性关系。</p><p>而在这里我们将会学习真正的深度神经网络。最简单的深度神经网络称为<strong>多层感知机</strong>。它由多层神经元组成，每一层从它的上一层接收输入，又向下一层输出。</p><p>这一节我们会学习更多的基础概念，如<strong>隐藏层</strong>和<strong>激活函数</strong>。</p><h2 id="_1-多层感知机的数学基础" tabindex="-1"><a class="header-anchor" href="#_1-多层感知机的数学基础"><span>1 多层感知机的数学基础</span></a></h2><p>线性回归和 softmax 回归都是线性模型。但是这个世界并不总是线性的。我们需要寻找一些变换来突破线性模型的限制。例如，我们可以在输入和输出之间添加一个或者多个函数，使其能处理更普遍的函数关系类型，也就是<strong>隐藏层</strong>。</p><p>我们以图的方式描述多层感知机。</p><div style="text-align:center;"><p><img src="https://oss.yoake.cc/art/deeplearning/1749124913031.webp" alt="1749124913031.webp"></p></div><p>图示的多层感知机共有两层（输入层不计入，因为输入层不参与计算）。假设两层均为线性模型，那么：</p><p>对于从输入层到隐藏层，有</p><p class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi mathvariant="bold-italic">H</mi><mo>=</mo><mi mathvariant="bold-italic">X</mi><msub><mi mathvariant="bold-italic">W</mi><mn>1</mn></msub><mo>+</mo><msub><mi mathvariant="bold-italic">b</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">\boldsymbol{H} = \boldsymbol{X} \boldsymbol{W}_1 + \boldsymbol{b}_1 </annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6861em;"></span><span class="mord"><span class="mord"><span class="mord boldsymbol" style="margin-right:0.08229em;">H</span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.8361em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord"><span class="mord boldsymbol" style="margin-right:0.07778em;">X</span></span></span><span class="mord"><span class="mord"><span class="mord"><span class="mord boldsymbol" style="margin-right:0.15972em;">W</span></span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.8444em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord"><span class="mord"><span class="mord boldsymbol">b</span></span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></span></p><p>对于从隐藏层到输出层，有</p><p class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi mathvariant="bold-italic">O</mi><mo>=</mo><mi mathvariant="bold-italic">H</mi><msub><mi mathvariant="bold-italic">W</mi><mn>2</mn></msub><mo>+</mo><msub><mi mathvariant="bold-italic">b</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">\boldsymbol{O} = \boldsymbol{H} \boldsymbol{W}_2 + \boldsymbol{b}_2 </annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6861em;"></span><span class="mord"><span class="mord"><span class="mord boldsymbol" style="margin-right:0.03194em;">O</span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.8361em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord"><span class="mord boldsymbol" style="margin-right:0.08229em;">H</span></span></span><span class="mord"><span class="mord"><span class="mord"><span class="mord boldsymbol" style="margin-right:0.15972em;">W</span></span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.8444em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord"><span class="mord"><span class="mord boldsymbol">b</span></span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></span></p><p>不难发现最终输出<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="bold-italic">O</mi></mrow><annotation encoding="application/x-tex">\boldsymbol{O}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6861em;"></span><span class="mord"><span class="mord"><span class="mord boldsymbol" style="margin-right:0.03194em;">O</span></span></span></span></span></span>仍然是输入<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="bold-italic">X</mi></mrow><annotation encoding="application/x-tex">\boldsymbol{X}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6861em;"></span><span class="mord"><span class="mord"><span class="mord boldsymbol" style="margin-right:0.07778em;">X</span></span></span></span></span></span>的线性函数。那么这使得隐藏层失去了原本的意义——我们想引入隐藏层以突破线性模型的限制。</p><p>这启发我们，在隐藏层处理结束后，应该对结果应用非线性函数，以保证多层感知机不会退化为线性模型。这个非线性函数称为<strong>激活函数</strong>。</p><p>为了构建更通用的多层感知机，我们可以继续堆叠隐藏层。通过简单隐藏层的堆叠，实现对复杂函数的精确模拟。理论上，具有足够隐藏单元的一层感知机就能逼近任意连续函数；而多层结构则可以用更少的神经元，更高效地表示复杂函数。</p><h3 id="_1-1-relu-函数及其导数" tabindex="-1"><a class="header-anchor" href="#_1-1-relu-函数及其导数"><span>1.1 ReLu 函数及其导数</span></a></h3><p><strong>修正线性单元</strong>（ReLU）提供了一种非常简单的非线性变换。</p><p class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mrow><mi mathvariant="normal">R</mi><mi mathvariant="normal">e</mi><mi mathvariant="normal">L</mi><mi mathvariant="normal">U</mi></mrow><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo>=</mo><mi>max</mi><mo>⁡</mo><mo stretchy="false">{</mo><mi>x</mi><mo separator="true">,</mo><mn>0</mn><mo stretchy="false">}</mo></mrow><annotation encoding="application/x-tex">{\rm ReLU}(x) = \max \{x, 0\} </annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord"><span class="mord mathrm">ReLU</span></span></span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mop">max</span><span class="mopen">{</span><span class="mord mathnormal">x</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord">0</span><span class="mclose">}</span></span></span></span></span></p><p>它的导数为</p><p class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mfrac><mi mathvariant="normal">d</mi><mrow><mi mathvariant="normal">d</mi><mi>x</mi></mrow></mfrac><mrow><mi mathvariant="normal">R</mi><mi mathvariant="normal">e</mi><mi mathvariant="normal">L</mi><mi mathvariant="normal">U</mi></mrow><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo>=</mo><mrow><mo fence="true">{</mo><mtable rowspacing="0.25em" columnalign="right" columnspacing=""><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mn>0</mn><mo separator="true">,</mo><mi>x</mi><mo>≤</mo><mn>0</mn></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mn>1</mn><mo separator="true">,</mo><mi>x</mi><mo>&gt;</mo><mn>0</mn></mrow></mstyle></mtd></mtr></mtable></mrow></mrow><annotation encoding="application/x-tex">\frac{\rm d}{{\rm d}x} {\rm ReLU}(x) = \left\{ \begin{aligned} 0, x \leq 0 \\ 1, x \gt 0 \\ \end{aligned} \right. </annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:2.0574em;vertical-align:-0.686em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.3714em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord"><span class="mord mathrm">d</span></span></span><span class="mord mathnormal">x</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord mathrm">d</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.686em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mord"><span class="mord"><span class="mord mathrm">ReLU</span></span></span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:3em;vertical-align:-1.25em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;"><span class="delimsizing size4">{</span></span><span class="mord"><span class="mtable"><span class="col-align-r"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.75em;"><span style="top:-3.91em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">0</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal">x</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">≤</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mord">0</span></span></span><span style="top:-2.41em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">1</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal">x</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">&gt;</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mord">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.25em;"><span></span></span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span></p><div class="hint-container tip"><p class="hint-container-title">提示</p><p>事实上，根据严格的数学定义，ReLU 函数在 0 处的导数不存在。但是我们可以忽略这种情况，因为输入可能永远都不为 0。在深度学习领域内，“如果微妙的边界条件很重要，那么我们很可能是在研究数学而非工程”。</p></div><h3 id="_1-2-sigmoid-函数及其导数" tabindex="-1"><a class="header-anchor" href="#_1-2-sigmoid-函数及其导数"><span>1.2 sigmoid 函数及其导数</span></a></h3><p>对于一个定义域为全体实数的函数，<strong>挤压函数</strong>（sigmoid）可以将输入变换为<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><mn>0</mn><mo separator="true">,</mo><mn>1</mn><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(0,1)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord">0</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord">1</span><span class="mclose">)</span></span></span></span>上的输出。</p><p class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mrow><mi mathvariant="normal">s</mi><mi mathvariant="normal">i</mi><mi mathvariant="normal">g</mi><mi mathvariant="normal">m</mi><mi mathvariant="normal">o</mi><mi mathvariant="normal">i</mi><mi mathvariant="normal">d</mi></mrow><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo>=</mo><mfrac><mn>1</mn><mrow><mn>1</mn><mo>+</mo><mi>exp</mi><mo>⁡</mo><mo stretchy="false">(</mo><mo>−</mo><mi>x</mi><mo stretchy="false">)</mo></mrow></mfrac></mrow><annotation encoding="application/x-tex">{\rm sigmoid}(x) = \frac{1}{1+\exp(-x)} </annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord"><span class="mord mathrm">sigmoid</span></span></span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:2.2574em;vertical-align:-0.936em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.3214em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">1</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mop">exp</span><span class="mopen">(</span><span class="mord">−</span><span class="mord mathnormal">x</span><span class="mclose">)</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.936em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span></p><p>它的导数为</p><p class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mfrac><mi mathvariant="normal">d</mi><mrow><mi mathvariant="normal">d</mi><mi>x</mi></mrow></mfrac><mrow><mi mathvariant="normal">s</mi><mi mathvariant="normal">i</mi><mi mathvariant="normal">g</mi><mi mathvariant="normal">m</mi><mi mathvariant="normal">o</mi><mi mathvariant="normal">i</mi><mi mathvariant="normal">d</mi></mrow><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo>=</mo><mfrac><mrow><mi>exp</mi><mo>⁡</mo><mo stretchy="false">(</mo><mo>−</mo><mi>x</mi><mo stretchy="false">)</mo></mrow><mrow><mo stretchy="false">(</mo><mn>1</mn><mo>+</mo><mi>exp</mi><mo>⁡</mo><mo stretchy="false">(</mo><mo>−</mo><mi>x</mi><mo stretchy="false">)</mo><msup><mo stretchy="false">)</mo><mn>2</mn></msup></mrow></mfrac><mo>=</mo><mrow><mi mathvariant="normal">s</mi><mi mathvariant="normal">i</mi><mi mathvariant="normal">g</mi><mi mathvariant="normal">m</mi><mi mathvariant="normal">o</mi><mi mathvariant="normal">i</mi><mi mathvariant="normal">d</mi></mrow><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo stretchy="false">(</mo><mn>1</mn><mo>−</mo><mrow><mi mathvariant="normal">s</mi><mi mathvariant="normal">i</mi><mi mathvariant="normal">g</mi><mi mathvariant="normal">m</mi><mi mathvariant="normal">o</mi><mi mathvariant="normal">i</mi><mi mathvariant="normal">d</mi></mrow><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\frac{\rm d}{{\rm d}x} {\rm sigmoid}(x) = \frac{\exp(-x)}{(1+\exp(-x))^2} = {\rm sigmoid}(x)(1- {\rm sigmoid}(x)) </annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:2.0574em;vertical-align:-0.686em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.3714em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord"><span class="mord mathrm">d</span></span></span><span class="mord mathnormal">x</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord mathrm">d</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.686em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mord"><span class="mord"><span class="mord mathrm">sigmoid</span></span></span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:2.363em;vertical-align:-0.936em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.427em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mopen">(</span><span class="mord">1</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mop">exp</span><span class="mopen">(</span><span class="mord">−</span><span class="mord mathnormal">x</span><span class="mclose">)</span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7401em;"><span style="top:-2.989em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mop">exp</span><span class="mopen">(</span><span class="mord">−</span><span class="mord mathnormal">x</span><span class="mclose">)</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.936em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord"><span class="mord mathrm">sigmoid</span></span></span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mclose">)</span><span class="mopen">(</span><span class="mord">1</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord"><span class="mord mathrm">sigmoid</span></span></span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mclose">))</span></span></span></span></span></p><h3 id="_1-3-tanh-函数及其导数" tabindex="-1"><a class="header-anchor" href="#_1-3-tanh-函数及其导数"><span>1.3 tanh 函数及其导数</span></a></h3><p>与 sigmoid 函数类似，<strong>双曲正切函数</strong>（tanh）可以将全体实数上的输入变换为<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><mo>−</mo><mn>1</mn><mo separator="true">,</mo><mn>1</mn><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(-1,1)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord">−</span><span class="mord">1</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord">1</span><span class="mclose">)</span></span></span></span>上的输出。</p><p class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>tanh</mi><mo>⁡</mo><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo>=</mo><mfrac><mrow><mn>1</mn><mo>−</mo><mi>exp</mi><mo>⁡</mo><mo stretchy="false">(</mo><mo>−</mo><mn>2</mn><mi>x</mi><mo stretchy="false">)</mo></mrow><mrow><mn>1</mn><mo>+</mo><mi>exp</mi><mo>⁡</mo><mo stretchy="false">(</mo><mo>−</mo><mn>2</mn><mi>x</mi><mo stretchy="false">)</mo></mrow></mfrac></mrow><annotation encoding="application/x-tex">\tanh(x) = \frac{1-\exp(-2x)}{1+\exp(-2x)} </annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mop">tanh</span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:2.363em;vertical-align:-0.936em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.427em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">1</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mop">exp</span><span class="mopen">(</span><span class="mord">−</span><span class="mord">2</span><span class="mord mathnormal">x</span><span class="mclose">)</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">1</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mop">exp</span><span class="mopen">(</span><span class="mord">−</span><span class="mord">2</span><span class="mord mathnormal">x</span><span class="mclose">)</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.936em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span></p><p>它的导数为</p><p class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mfrac><mi mathvariant="normal">d</mi><mrow><mi mathvariant="normal">d</mi><mi>x</mi></mrow></mfrac><mi>tanh</mi><mo>⁡</mo><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo>=</mo><mn>1</mn><mo>−</mo><msup><mrow><mi>tanh</mi><mo>⁡</mo></mrow><mn>2</mn></msup><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\frac{\rm d}{{\rm d}x} \tanh(x) = 1-\tanh^2 (x) </annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:2.0574em;vertical-align:-0.686em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.3714em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord"><span class="mord mathrm">d</span></span></span><span class="mord mathnormal">x</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord mathrm">d</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.686em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mop">tanh</span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em;"></span><span class="mord">1</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1.1484em;vertical-align:-0.25em;"></span><span class="mop"><span class="mop">tanh</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8984em;"><span style="top:-3.1473em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mclose">)</span></span></span></span></span></p><h2 id="_2-从框架实现多层感知机" tabindex="-1"><a class="header-anchor" href="#_2-从框架实现多层感知机"><span>2 从框架实现多层感知机</span></a></h2><p>我们还是以 softmax 回归时用的 Fashion-MINST 数据集训练。</p><p>与 softmax 的框架实现相比，唯一的区别就是在定义网络时添加了一层 ReLU 函数和一层线性层。</p><div class="language-python line-numbers-mode" data-highlighter="shiki" data-ext="python" style="--shiki-light:#393a34;--shiki-dark:#dbd7caee;--shiki-light-bg:#ffffff;--shiki-dark-bg:#121212;"><pre class="shiki shiki-themes vitesse-light vitesse-dark vp-code"><code class="language-python"><span class="line"><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">net </span><span style="--shiki-light:#999999;--shiki-dark:#666666;">=</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;"> nn</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">.</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">Sequential</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">(</span></span>
<span class="line"><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">    nn</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">.</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">Flatten</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">(),</span></span>
<span class="line"><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">    nn</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">.</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">Linear</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">(</span><span style="--shiki-light:#2F798A;--shiki-dark:#4C9A91;">784</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">,</span><span style="--shiki-light:#2F798A;--shiki-dark:#4C9A91;"> 256</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">),</span></span>
<span class="line"><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">    nn</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">.</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">ReLU</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">(),</span></span>
<span class="line"><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">    nn</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">.</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">Linear</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">(</span><span style="--shiki-light:#2F798A;--shiki-dark:#4C9A91;">256</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">,</span><span style="--shiki-light:#2F798A;--shiki-dark:#4C9A91;"> 10</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">),</span></span>
<span class="line"><span style="--shiki-light:#999999;--shiki-dark:#666666;">)</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>其他部分完全一致。</p><p>可以看到，在经过 10 轮训练后，损失函数和准确率都比 softmax 回归好很多。</p><div class="language-text line-numbers-mode" data-highlighter="shiki" data-ext="text" style="--shiki-light:#393a34;--shiki-dark:#dbd7caee;--shiki-light-bg:#ffffff;--shiki-dark-bg:#121212;"><pre class="shiki shiki-themes vitesse-light vitesse-dark vp-code"><code class="language-text"><span class="line"><span>epoch 1, train loss 1.046, train acc 0.634, test acc 0.717</span></span>
<span class="line"><span>epoch 2, train loss 0.603, train acc 0.789, test acc 0.777</span></span>
<span class="line"><span>epoch 3, train loss 0.522, train acc 0.818, test acc 0.812</span></span>
<span class="line"><span>epoch 4, train loss 0.481, train acc 0.833, test acc 0.830</span></span>
<span class="line"><span>epoch 5, train loss 0.452, train acc 0.841, test acc 0.834</span></span>
<span class="line"><span>epoch 6, train loss 0.434, train acc 0.847, test acc 0.832</span></span>
<span class="line"><span>epoch 7, train loss 0.416, train acc 0.853, test acc 0.838</span></span>
<span class="line"><span>epoch 8, train loss 0.405, train acc 0.857, test acc 0.808</span></span>
<span class="line"><span>epoch 9, train loss 0.391, train acc 0.862, test acc 0.826</span></span>
<span class="line"><span>epoch 10, train loss 0.382, train acc 0.864, test acc 0.855</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>那我们继续叠加激活函数，训练表现会不会更好呢？很遗憾，并不会。简单堆叠层数并不总是带来性能提升。</p><div class="language-python line-numbers-mode" data-highlighter="shiki" data-ext="python" style="--shiki-light:#393a34;--shiki-dark:#dbd7caee;--shiki-light-bg:#ffffff;--shiki-dark-bg:#121212;"><pre class="shiki shiki-themes vitesse-light vitesse-dark vp-code"><code class="language-python"><span class="line"><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">net </span><span style="--shiki-light:#999999;--shiki-dark:#666666;">=</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;"> nn</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">.</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">Sequential</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">(</span></span>
<span class="line"><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">    nn</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">.</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">Flatten</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">(),</span></span>
<span class="line"><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">    nn</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">.</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">Linear</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">(</span><span style="--shiki-light:#2F798A;--shiki-dark:#4C9A91;">784</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">,</span><span style="--shiki-light:#2F798A;--shiki-dark:#4C9A91;"> 256</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">),</span></span>
<span class="line"><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">    nn</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">.</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">ReLU</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">(),</span></span>
<span class="line"><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">    nn</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">.</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">Linear</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">(</span><span style="--shiki-light:#2F798A;--shiki-dark:#4C9A91;">256</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">,</span><span style="--shiki-light:#2F798A;--shiki-dark:#4C9A91;"> 128</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">),</span></span>
<span class="line"><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">    nn</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">.</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">ReLU</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">(),</span></span>
<span class="line"><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">    nn</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">.</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">Linear</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">(</span><span style="--shiki-light:#2F798A;--shiki-dark:#4C9A91;">128</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">,</span><span style="--shiki-light:#2F798A;--shiki-dark:#4C9A91;"> 10</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">)</span></span>
<span class="line"><span style="--shiki-light:#999999;--shiki-dark:#666666;">)</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><div class="language-text line-numbers-mode" data-highlighter="shiki" data-ext="text" style="--shiki-light:#393a34;--shiki-dark:#dbd7caee;--shiki-light-bg:#ffffff;--shiki-dark-bg:#121212;"><pre class="shiki shiki-themes vitesse-light vitesse-dark vp-code"><code class="language-text"><span class="line"><span>epoch 1, train loss 1.860, train acc 0.299, test acc 0.526</span></span>
<span class="line"><span>epoch 2, train loss 0.914, train acc 0.652, test acc 0.613</span></span>
<span class="line"><span>epoch 3, train loss 0.691, train acc 0.750, test acc 0.750</span></span>
<span class="line"><span>epoch 4, train loss 0.590, train acc 0.788, test acc 0.799</span></span>
<span class="line"><span>epoch 5, train loss 0.527, train acc 0.811, test acc 0.810</span></span>
<span class="line"><span>epoch 6, train loss 0.489, train acc 0.824, test acc 0.802</span></span>
<span class="line"><span>epoch 7, train loss 0.458, train acc 0.835, test acc 0.834</span></span>
<span class="line"><span>epoch 8, train loss 0.433, train acc 0.843, test acc 0.838</span></span>
<span class="line"><span>epoch 9, train loss 0.417, train acc 0.849, test acc 0.821</span></span>
<span class="line"><span>epoch 10, train loss 0.403, train acc 0.855, test acc 0.827</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h2 id="_3-过拟合和泛化误差" tabindex="-1"><a class="header-anchor" href="#_3-过拟合和泛化误差"><span>3 过拟合和泛化误差</span></a></h2><p>我们的训练目标是想要模型从有限的数据中学习到一类通用的模式，以对未知数据进行预测，即前面提到的<strong>泛化</strong>。</p><p>上面提到过继续叠加激活函数并不会使训练效果更好，反而会出现<strong>过拟合</strong>现象。当模型在训练数据上拟合的比在潜在分布中更接近时，我们说发生了过拟合。</p><p>可以这么简单理解，过拟合就像一个死记硬背练习题的学生，当考试时出现他从没见过的题目时，就会无所适从。</p><p>当神经元、层数、迭代次数足够多时，模型最终可以在训练集上达到完美的精度，但是在测试集上的准确性却下降了，即发生了过拟合。</p><p>我们使用泛化误差讨论过拟合的程度。<strong>泛化误差</strong>是指，模型应用在同样从原始样本的分布中抽取的无限多数据样本时，模型误差的期望。</p><p>由于我们不可能收集到无限多的样本，因此实际上我们从数据集中抽取一部分来估计泛化误差，也就是<strong>验证集</strong>。和测试集一样，验证集也是随机选取、与训练集不能产生重合部分。</p><p>因此我们的数据会被分成三份：训练集、验证集和测试集。在我们确认所有的超参数之前，不应该使用测试集。</p><h2 id="_4-正则化和权重衰减" tabindex="-1"><a class="header-anchor" href="#_4-正则化和权重衰减"><span>4 正则化和权重衰减</span></a></h2><p>对抗过拟合的方法称之为<strong>正则化</strong>，<strong>权重衰减</strong>是最广泛使用的正则化技术之一。</p><p>权重衰减通过计算函数与 0 的距离来衡量函数的复杂度。一种简单的方法是通过线性函数 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>f</mi><mo stretchy="false">(</mo><mi mathvariant="bold-italic">x</mi><mo stretchy="false">)</mo><mo>=</mo><msup><mi mathvariant="bold-italic">w</mi><mi>T</mi></msup><mi mathvariant="bold-italic">x</mi></mrow><annotation encoding="application/x-tex">f(\boldsymbol{x}) = \boldsymbol{w}^T \boldsymbol{x}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="mopen">(</span><span class="mord"><span class="mord"><span class="mord boldsymbol">x</span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.8413em;"></span><span class="mord"><span class="mord"><span class="mord"><span class="mord boldsymbol" style="margin-right:0.02778em;">w</span></span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">T</span></span></span></span></span></span></span></span><span class="mord"><span class="mord"><span class="mord boldsymbol">x</span></span></span></span></span></span> 中权重向量 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="bold-italic">w</mi></mrow><annotation encoding="application/x-tex">\boldsymbol{w}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4444em;"></span><span class="mord"><span class="mord"><span class="mord boldsymbol" style="margin-right:0.02778em;">w</span></span></span></span></span></span> 的 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>L</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">L_2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">L</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 范数的平方 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">∣</mi><mi mathvariant="normal">∣</mi><mi mathvariant="bold-italic">w</mi><mi mathvariant="normal">∣</mi><msup><mi mathvariant="normal">∣</mi><mn>2</mn></msup></mrow><annotation encoding="application/x-tex">||\boldsymbol{w}||^2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0641em;vertical-align:-0.25em;"></span><span class="mord">∣∣</span><span class="mord"><span class="mord"><span class="mord boldsymbol" style="margin-right:0.02778em;">w</span></span></span><span class="mord">∣</span><span class="mord"><span class="mord">∣</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span></span> 来度量其复杂度。</p><p>例如对于线性回归模型的损失函数：</p><p class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>L</mi><mo stretchy="false">(</mo><mi mathvariant="bold-italic">w</mi><mo separator="true">,</mo><mi>b</mi><mo stretchy="false">)</mo><mo>=</mo><mfrac><mn>1</mn><mi>n</mi></mfrac><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><mfrac><mn>1</mn><mn>2</mn></mfrac><msup><mrow><mo fence="true">(</mo><msup><mi mathvariant="bold-italic">w</mi><mi>T</mi></msup><msub><mi mathvariant="bold-italic">x</mi><mi>i</mi></msub><mo>+</mo><mi>b</mi><mo>−</mo><msub><mi>y</mi><mi>i</mi></msub><mo fence="true">)</mo></mrow><mn>2</mn></msup></mrow><annotation encoding="application/x-tex">L(\boldsymbol{w}, b) = \frac{1}{n} \sum_{i=1}^n \frac{1}{2} \left( \boldsymbol{w}^T \boldsymbol{x}_i + b - y_i \right)^2 </annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">L</span><span class="mopen">(</span><span class="mord"><span class="mord"><span class="mord boldsymbol" style="margin-right:0.02778em;">w</span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal">b</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:2.9291em;vertical-align:-1.2777em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.3214em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal">n</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.686em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.6514em;"><span style="top:-1.8723em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.05em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span><span style="top:-4.3em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.2777em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.3214em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">2</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.686em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="minner"><span class="minner"><span class="mopen delimcenter" style="top:0em;"><span class="delimsizing size1">(</span></span><span class="mord"><span class="mord"><span class="mord"><span class="mord boldsymbol" style="margin-right:0.02778em;">w</span></span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8913em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">T</span></span></span></span></span></span></span></span><span class="mord"><span class="mord"><span class="mord"><span class="mord boldsymbol">x</span></span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mord mathnormal">b</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose delimcenter" style="top:0em;"><span class="delimsizing size1">)</span></span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:1.0953em;"><span style="top:-3.3442em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span></span></span></p><p>加入对权重向量 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="bold-italic">w</mi></mrow><annotation encoding="application/x-tex">\boldsymbol{w}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4444em;"></span><span class="mord"><span class="mord"><span class="mord boldsymbol" style="margin-right:0.02778em;">w</span></span></span></span></span></span> 的惩罚项：</p><p class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>L</mi><mo stretchy="false">(</mo><mi mathvariant="bold-italic">w</mi><mo separator="true">,</mo><mi>b</mi><mo stretchy="false">)</mo><mo>+</mo><mfrac><mi>λ</mi><mn>2</mn></mfrac><mi mathvariant="normal">∣</mi><mi mathvariant="normal">∣</mi><mi mathvariant="bold-italic">w</mi><mi mathvariant="normal">∣</mi><msup><mi mathvariant="normal">∣</mi><mn>2</mn></msup></mrow><annotation encoding="application/x-tex">L(\boldsymbol{w}, b) + \frac{\lambda}{2}||\boldsymbol{w}||^2 </annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">L</span><span class="mopen">(</span><span class="mord"><span class="mord"><span class="mord boldsymbol" style="margin-right:0.02778em;">w</span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal">b</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:2.0574em;vertical-align:-0.686em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.3714em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">2</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal">λ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.686em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mord">∣∣</span><span class="mord"><span class="mord"><span class="mord boldsymbol" style="margin-right:0.02778em;">w</span></span></span><span class="mord">∣</span><span class="mord"><span class="mord">∣</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8641em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span></span></span></p><p>这里的系数 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mn>1</mn><mn>2</mn></mfrac></mrow><annotation encoding="application/x-tex">\frac{1}{2}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.1901em;vertical-align:-0.345em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8451em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.345em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span> 是为了求导后能使系数为 1。<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>λ</mi></mrow><annotation encoding="application/x-tex">\lambda</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord mathnormal">λ</span></span></span></span> 是一个新的超参数<strong>正则化常数</strong>，它用于限制 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">∣</mi><mi mathvariant="normal">∣</mi><mi mathvariant="bold-italic">w</mi><mi mathvariant="normal">∣</mi><mi mathvariant="normal">∣</mi></mrow><annotation encoding="application/x-tex">||\boldsymbol{w}||</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord">∣∣</span><span class="mord"><span class="mord"><span class="mord boldsymbol" style="margin-right:0.02778em;">w</span></span></span><span class="mord">∣∣</span></span></span></span> 的大小。</p><p>PyTorch 中已经集成了权重衰减模块，以<a class="vp-link link" href="/deeplearning/basic/03/#_3-4-%E8%AE%AD%E7%BB%83"><!--[-->线性神经网络<!--]--><!----></a>为例，要加入权重衰减，只需要：</p><div class="language-python line-numbers-mode" data-highlighter="shiki" data-ext="python" style="--shiki-light:#393a34;--shiki-dark:#dbd7caee;--shiki-light-bg:#ffffff;--shiki-dark-bg:#121212;"><pre class="shiki shiki-themes vitesse-light vitesse-dark vp-code"><code class="language-python"><span class="line"><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">optimizer </span><span style="--shiki-light:#999999;--shiki-dark:#666666;">=</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;"> torch</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">.</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">optim</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">.</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">SGD</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">([</span></span>
<span class="line"><span style="--shiki-light:#999999;--shiki-dark:#666666;">    {</span><span style="--shiki-light:#B5695977;--shiki-dark:#C98A7D77;">&#39;</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;">params</span><span style="--shiki-light:#B5695977;--shiki-dark:#C98A7D77;">&#39;</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">:</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;"> net</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">[</span><span style="--shiki-light:#2F798A;--shiki-dark:#4C9A91;">0</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">].</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">weight</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">,</span><span style="--shiki-light:#B5695977;--shiki-dark:#C98A7D77;"> &#39;</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;">wd</span><span style="--shiki-light:#B5695977;--shiki-dark:#C98A7D77;">&#39;</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">:</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;"> wd</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">},</span></span>
<span class="line"><span style="--shiki-light:#999999;--shiki-dark:#666666;">    {</span><span style="--shiki-light:#B5695977;--shiki-dark:#C98A7D77;">&#39;</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;">params</span><span style="--shiki-light:#B5695977;--shiki-dark:#C98A7D77;">&#39;</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">:</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;"> net</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">[</span><span style="--shiki-light:#2F798A;--shiki-dark:#4C9A91;">0</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">].</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">bias</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">,</span><span style="--shiki-light:#B5695977;--shiki-dark:#C98A7D77;"> &#39;</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;">lr</span><span style="--shiki-light:#B5695977;--shiki-dark:#C98A7D77;">&#39;</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">:</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;"> lr</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">}</span></span>
<span class="line"><span style="--shiki-light:#999999;--shiki-dark:#666666;">])</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>这里采用数组形式，是因为偏置参数<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>b</mi></mrow><annotation encoding="application/x-tex">b</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord mathnormal">b</span></span></span></span>并不参与到正则化中来，因此我们选择对权重和偏置分别设置超参数。在调用时中传入<code>wd</code>参数即可。</p><h2 id="_5-暂退法" tabindex="-1"><a class="header-anchor" href="#_5-暂退法"><span>5 暂退法</span></a></h2><p>我们先来思考一下什么是一个好的深度学习模型。我们希望这个模型能在未知的数据上也有较好的预测表现，并且对于相同或者相似的输入能得到相同或者相似的输出，也就是平滑性。例如当我们对图像进行分类时，向图像内加入一些随机噪声应该是基本无影响的。因此有人提出一个想法：在训练过程中，在后续计算层之前向网络的每一层注入噪声。因为当训练一个多层的神经网络时，注入噪声只会在输入-输出映射上增强平滑性。这个想法就是<strong>暂退法</strong>。</p><p>从表面上看，在每次训练迭代过程中，暂退法在计算下一层之前将当前层中的一些节点置零，也就是丢弃某些神经元。</p><p>在标准暂退法正则化中，每个中间值 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>h</mi></mrow><annotation encoding="application/x-tex">h</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord mathnormal">h</span></span></span></span> 以暂退概率 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi></mrow><annotation encoding="application/x-tex">p</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em;"></span><span class="mord mathnormal">p</span></span></span></span> 被随机变量 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>h</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup></mrow><annotation encoding="application/x-tex">h&#39;</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7519em;"></span><span class="mord"><span class="mord mathnormal">h</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7519em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span></span></span></span> 替换，即：</p><p class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msup><mi>h</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup><mo>=</mo><mrow><mo fence="true">{</mo><mtable rowspacing="0.25em" columnalign="right" columnspacing=""><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mn>0</mn><mo separator="true">,</mo><mtext>概率为</mtext><mi>p</mi></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mfrac><mi>h</mi><mrow><mn>1</mn><mo>−</mo><mi>p</mi></mrow></mfrac><mo separator="true">,</mo><mtext>其他情况</mtext></mrow></mstyle></mtd></mtr></mtable></mrow></mrow><annotation encoding="application/x-tex">h&#39; = \left\{ \begin{aligned} 0, \text{概率为}p \\ \frac{h}{1-p}, \text{其他情况} \\ \end{aligned} \right. </annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8019em;"></span><span class="mord"><span class="mord mathnormal">h</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8019em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:4.2em;vertical-align:-1.85em;"></span><span class="minner"><span class="mopen"><span class="delimsizing mult"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:2.35em;"><span style="top:-2.2em;"><span class="pstrut" style="height:3.15em;"></span><span class="delimsizinginner delim-size4"><span>⎩</span></span></span><span style="top:-2.192em;"><span class="pstrut" style="height:3.15em;"></span><span style="height:0.316em;width:0.8889em;"><svg xmlns="http://www.w3.org/2000/svg" width="0.8889em" height="0.316em" style="width:0.8889em;" viewBox="0 0 888.89 316" preserveAspectRatio="xMinYMin"><path d="M384 0 H504 V316 H384z M384 0 H504 V316 H384z"></path></svg></span></span><span style="top:-3.15em;"><span class="pstrut" style="height:3.15em;"></span><span class="delimsizinginner delim-size4"><span>⎨</span></span></span><span style="top:-4.292em;"><span class="pstrut" style="height:3.15em;"></span><span style="height:0.316em;width:0.8889em;"><svg xmlns="http://www.w3.org/2000/svg" width="0.8889em" height="0.316em" style="width:0.8889em;" viewBox="0 0 888.89 316" preserveAspectRatio="xMinYMin"><path d="M384 0 H504 V316 H384z M384 0 H504 V316 H384z"></path></svg></span></span><span style="top:-4.6em;"><span class="pstrut" style="height:3.15em;"></span><span class="delimsizinginner delim-size4"><span>⎧</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.85em;"><span></span></span></span></span></span></span><span class="mord"><span class="mtable"><span class="col-align-r"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:2.2759em;"><span style="top:-4.8074em;"><span class="pstrut" style="height:3.3714em;"></span><span class="mord"><span class="mord">0</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord text"><span class="mord cjk_fallback">概率为</span></span><span class="mord mathnormal">p</span></span></span><span style="top:-2.7759em;"><span class="pstrut" style="height:3.3714em;"></span><span class="mord"><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.3714em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">1</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mord mathnormal">p</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal">h</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.8804em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord text"><span class="mord cjk_fallback">其他情况</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.7759em;"><span></span></span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span></p><p>这样在替换后，整层的期望保持不变，即 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>E</mi><mo stretchy="false">[</mo><msup><mi>h</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup><mo stretchy="false">]</mo><mo>=</mo><mi>h</mi></mrow><annotation encoding="application/x-tex">E[h&#39;] = h</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0019em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.05764em;">E</span><span class="mopen">[</span><span class="mord"><span class="mord mathnormal">h</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7519em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span><span class="mclose">]</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord mathnormal">h</span></span></span></span>。</p><div style="text-align:center;"><p><img src="https://oss.yoake.cc/art/deeplearning/1753692813234.webp" alt="1753692813234.webp"></p></div><p>经过暂退法处理后，可以有效避免模型过度依赖某一神经元的情况，提高平滑性。</p><p>对于 PyTorch，我们只需要在每个全连接层之后添加一个<code>Dropout</code>层，并传入暂退概率即可：</p><div class="language-python line-numbers-mode" data-highlighter="shiki" data-ext="python" style="--shiki-light:#393a34;--shiki-dark:#dbd7caee;--shiki-light-bg:#ffffff;--shiki-dark-bg:#121212;"><pre class="shiki shiki-themes vitesse-light vitesse-dark vp-code"><code class="language-python"><span class="line"><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">net </span><span style="--shiki-light:#999999;--shiki-dark:#666666;">=</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;"> nn</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">.</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">Sequential</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">(</span></span>
<span class="line"><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">    nn</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">.</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">Flatten</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">(),</span></span>
<span class="line"><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">    nn</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">.</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">Linear</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">(</span><span style="--shiki-light:#2F798A;--shiki-dark:#4C9A91;">784</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">,</span><span style="--shiki-light:#2F798A;--shiki-dark:#4C9A91;"> 256</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">),</span></span>
<span class="line"><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">    nn</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">.</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">ReLU</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">(),</span></span>
<span class="line"><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">    nn</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">.</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">Dropout</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">(</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">p1</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">)</span><span style="--shiki-light:#A0ADA0;--shiki-dark:#758575DD;"> # 第一次暂退</span></span>
<span class="line"><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">    nn</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">.</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">Linear</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">(</span><span style="--shiki-light:#2F798A;--shiki-dark:#4C9A91;">256</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">,</span><span style="--shiki-light:#2F798A;--shiki-dark:#4C9A91;"> 128</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">),</span></span>
<span class="line"><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">    nn</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">.</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">ReLU</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">(),</span></span>
<span class="line"><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">    nn</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">.</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">Dropout</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">(</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">p2</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">)</span><span style="--shiki-light:#A0ADA0;--shiki-dark:#758575DD;"> # 第二次暂退</span></span>
<span class="line"><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">    nn</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">.</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">Linear</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">(</span><span style="--shiki-light:#2F798A;--shiki-dark:#4C9A91;">128</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">,</span><span style="--shiki-light:#2F798A;--shiki-dark:#4C9A91;"> 10</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">)</span></span>
<span class="line"><span style="--shiki-light:#999999;--shiki-dark:#666666;">)</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div></div><!----><!----><!----></div></main><footer class="vp-doc-footer" data-v-1b79a3f7 data-v-da62d186><!--[--><!--]--><!----><!----><nav class="prev-next" data-v-da62d186><div class="pager" data-v-da62d186><a class="vp-link link pager-link prev" href="/deeplearning/basic/04/" data-v-da62d186><!--[--><span class="desc" data-v-da62d186>上一页</span><span class="title" data-v-da62d186>Part 4 softmax 回归</span><!--]--><!----></a></div><div class="pager" data-v-da62d186><a class="vp-link link pager-link next" href="/deeplearning/cnn/01/" data-v-da62d186><!--[--><span class="desc" data-v-da62d186>下一页</span><span class="title" data-v-da62d186>Part 1 卷积神经网络基本原理</span><!--]--><!----></a></div></nav></footer><!----><!--[--><!--]--></div></div></div><!--[--><!--]--></div></div><!--]--><button type="button" class="vp-back-to-top" aria-label="back to top" data-v-b0769c2c style="display:none;" data-v-4a64d39e><span class="percent" data-allow-mismatch data-v-4a64d39e>0%</span><span class="show icon vpi-back-to-top" data-v-4a64d39e></span><svg aria-hidden="true" data-v-4a64d39e><circle cx="50%" cy="50%" data-allow-mismatch style="stroke-dasharray:calc(0% - 12.566370614359172px) calc(314.1592653589793% - 12.566370614359172px);" data-v-4a64d39e></circle></svg></button><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" aria-label="sign down" class="vp-sign-down" aria-hidden="true" data-v-b0769c2c style="display:none;" data-v-915d80b0><g fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2.5" data-v-915d80b0><path d="m19 11l-7 6l-7-6" data-v-915d80b0></path><path d="m19 5l-7 6l-7-6" opacity="0.6" data-v-915d80b0></path></g></svg><footer class="vp-footer has-sidebar" vp-footer data-v-b0769c2c data-v-0c5e895c><!--[--><div class="container" data-v-0c5e895c><p class="message" data-v-0c5e895c>
        <span style="user-select:none;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;">
          Copyright ©️ 2024 - 2025 YOAKE | Powered by <a href="https://v2.vuepress.vuejs.org/">VuePress</a> & <a href="https://theme-plume.vuejs.press/">Plume</a>
        </span>
        <br/>
        <span style="font-size:11px;user-select:none;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;">
          冀 ICP 备 2025102465号-1 · 京公网安备 11011502038573 号
        </span></p><!----></div><!--]--></footer><!--[--><!--]--><!--]--></div><!----><!--]--><!--[--><!--]--><!--]--></div><script type="module" src="/assets/app-BvfsiuvN.js" defer></script></body></html>